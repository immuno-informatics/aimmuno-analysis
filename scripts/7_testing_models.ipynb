{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "679f172b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a88f36",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d6377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import metrics\n",
    "\n",
    "from tape import ProteinBertModel, TAPETokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_seed = 22\n",
    "\n",
    "_ = torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8612ff48",
   "metadata": {},
   "source": [
    "Define paths and experiment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83c7829",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"/path/to/project/root\"\n",
    "\n",
    "data_dir = project_dir + \"/data\"\n",
    "models_dir = data_dir + \"/models\"\n",
    "temp_dir = project_dir + \"/temp\"\n",
    "datasets_dir = data_dir + \"/datasets\"\n",
    "\n",
    "hla_seqs_file = data_dir + \"/carmen-hla-sequences.parquet\"\n",
    "\n",
    "time_stamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "\n",
    "temp_output_no_hla_file = temp_dir + f\"/test_prediction_no_hla_{time_stamp}\"\n",
    "temp_output_hla_file = temp_dir + f\"/test_prediction_with_hla_{time_stamp}\"\n",
    "\n",
    "temp_output_no_hla_flat_file = temp_dir + f\"/test_prediction_no_hla_flat_{time_stamp}\"\n",
    "temp_output_hla_flat_file = temp_dir + f\"/test_prediction_with_hla_flat_{time_stamp}\"\n",
    "\n",
    "if not os.path.exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "\n",
    "dataset_src_col_pep = \"peptide\"\n",
    "dataset_src_col_label = \"label\"\n",
    "dataset_src_col_hla_seq = \"Sequence\"\n",
    "\n",
    "dataset_true_col_pep = \"peptide\"\n",
    "dataset_true_col_hla_seq = \"mhc\"\n",
    "dataset_true_col_label = \"label\"\n",
    "\n",
    "dataset_decoys_col_pep = \"peptide_rand\"\n",
    "dataset_decoys_col_hla_seq = \"mhc_rand\"\n",
    "dataset_decoys_col_label = \"label\"\n",
    "\n",
    "model_type = \"tape\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4140f288",
   "metadata": {},
   "source": [
    "Select experiment type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c2a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"carmen_balanced_1_1\"\n",
    "\n",
    "# exp_name = \"carmen_balanced_1_5\"\n",
    "\n",
    "# exp_name = \"carmen_unbalanced_1_1\"\n",
    "\n",
    "# exp_name = \"carmen_unbalanced_1_5\"\n",
    "\n",
    "# exp_name = \"synthetic_easy\"\n",
    "\n",
    "# exp_name = \"synthetic_hard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ec989",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_no_hla_file = models_dir + f\"/model_{model_type}_{exp_name}_no_hla.pt\"\n",
    "weights_hla_file = models_dir + f\"/model_{model_type}_{exp_name}_with_hla.pt\"\n",
    "\n",
    "test_set_dir = datasets_dir + f\"/{exp_name}\"\n",
    "\n",
    "carmen_test_file = test_set_dir + \"/test_set.csv\"\n",
    "\n",
    "synthetic_true_test_file = test_set_dir + \"/true_dataset_test.csv\"\n",
    "synthetic_decoys_test_file = test_set_dir + \"/decoys_dataset_test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42362079",
   "metadata": {},
   "source": [
    "Import the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c16e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TAPETokenizer(vocab=\"iupac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16af3794",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec11102",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TAPEClassification(nn.Module):\n",
    "    def __init__(self, input_dim_bert, output_dim):\n",
    "        super().__init__()\n",
    "        self.bert = ProteinBertModel.from_pretrained(\"bert-base\")\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(input_dim_bert, output_dim)\n",
    "\n",
    "    def forward(self, x_sem):\n",
    "        pooled_output = self.bert(x_sem)[0][:, 0, :]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        out = self.classifier(pooled_output)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3243dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TAPEClassification(768, 2)\n",
    "\n",
    "model.load_state_dict(torch.load(weights_no_hla_file))\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02ecec1",
   "metadata": {},
   "source": [
    "# STEP 1: No HLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97830d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exp_name.startswith(\"carmen_\"):\n",
    "    df_test = pd.read_csv(carmen_test_file)\n",
    "\n",
    "    test_peptides = df_test.peptide.values\n",
    "    test_labels_no_hla = df_test.label.values\n",
    "elif exp_name.startswith(\"synthetic_\"):\n",
    "    dataset_true_test = pd.read_csv(synthetic_true_test_file, index_col=0)\n",
    "    dataset_decoys_test = pd.read_csv(synthetic_decoys_test_file, index_col=0)\n",
    "\n",
    "    dataset_true_test = dataset_true_test.rename(\n",
    "        columns={dataset_true_col_hla_seq: dataset_src_col_hla_seq}\n",
    "    )\n",
    "    dataset_decoys_test = dataset_decoys_test[\n",
    "        [dataset_decoys_col_pep, dataset_decoys_col_label, dataset_decoys_col_hla_seq]\n",
    "    ].rename(\n",
    "        columns={\n",
    "            dataset_decoys_col_pep: dataset_src_col_pep,\n",
    "            dataset_decoys_col_hla_seq: dataset_src_col_hla_seq,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df_test = pd.concat(\n",
    "        [dataset_true_test, dataset_decoys_test], ignore_index=True, axis=0\n",
    "    )\n",
    "\n",
    "    del dataset_true_test, dataset_decoys_test\n",
    "\n",
    "    df_test[dataset_src_col_label] = df_test[dataset_src_col_label].replace(\n",
    "        {True: 1, False: 0}\n",
    "    )\n",
    "\n",
    "    test_peptides = df_test.peptide.values\n",
    "    test_labels_no_hla = df_test.label.values\n",
    "\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc14c7da",
   "metadata": {},
   "source": [
    "Tokenize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7497b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokenizing inputs\")\n",
    "\n",
    "tokenized_test_peptide = [tokenizer.encode(sent) for sent in test_peptides]\n",
    "tokenized_test = pad_sequences(\n",
    "    [sent for sent in tokenized_test_peptide],\n",
    "    dtype=\"long\",\n",
    "    truncating=\"post\",\n",
    "    padding=\"post\",\n",
    ")\n",
    "\n",
    "test_inputs = torch.tensor(tokenized_test)\n",
    "test_labels = torch.tensor(test_labels_no_hla)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_labels)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c9fab",
   "metadata": {},
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca6365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(temp_output_no_hla_file, \"w\") as f:\n",
    "    pass\n",
    "with open(temp_output_no_hla_flat_file, \"w\") as f:\n",
    "    pass\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for batch in tqdm(test_dataloader, desc=\"Testing 'no HLA' model\"):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(b_input_ids)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    with open(temp_output_no_hla_file, \"a\") as f:\n",
    "        for elem in logits[:, 1]:\n",
    "            f.write(str(elem) + \" \")\n",
    "\n",
    "    flat_predictions = np.argmax(logits, axis=1).flatten()\n",
    "    with open(temp_output_no_hla_flat_file, \"a\") as f:\n",
    "        for elem in flat_predictions:\n",
    "            f.write(str(elem) + \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a081573f",
   "metadata": {},
   "source": [
    "# STEP 2: With HLA\n",
    "\n",
    "Import the HLA sequence file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09129302",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exp_name.startswith(\"carmen_\"):\n",
    "    df_test_HLA = pd.read_csv(carmen_test_file)\n",
    "    HLA_df = pd.read_parquet(hla_seqs_file)\n",
    "    HLA_df = HLA_df.rename(columns={\"Allele\": \"HLA\"})\n",
    "    df_test_HLA = df_test_HLA.merge(HLA_df, on=\"HLA\")\n",
    "    df_test_HLA = df_test_HLA.drop(columns=[\"Pseudo_sequence\"])\n",
    "\n",
    "    test_peptides = df_test_HLA.peptide.values\n",
    "    HLA_sequences = df_test_HLA.Sequence.values\n",
    "    test_labels_with_hla = df_test_HLA.label.values\n",
    "elif exp_name.startswith(\"synthetic_\"):\n",
    "    dataset_true_test = pd.read_csv(synthetic_true_test_file, index_col=0)\n",
    "    dataset_decoys_test = pd.read_csv(synthetic_decoys_test_file, index_col=0)\n",
    "\n",
    "    dataset_true_test = dataset_true_test.rename(\n",
    "        columns={dataset_true_col_hla_seq: dataset_src_col_hla_seq}\n",
    "    )\n",
    "    dataset_decoys_test = dataset_decoys_test[\n",
    "        [dataset_decoys_col_pep, dataset_decoys_col_label, dataset_decoys_col_hla_seq]\n",
    "    ].rename(\n",
    "        columns={\n",
    "            dataset_decoys_col_pep: dataset_src_col_pep,\n",
    "            dataset_decoys_col_hla_seq: dataset_src_col_hla_seq,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df_test_HLA = pd.concat(\n",
    "        [dataset_true_test, dataset_decoys_test], ignore_index=True, axis=0\n",
    "    )\n",
    "\n",
    "    del dataset_true_test, dataset_decoys_test\n",
    "\n",
    "    df_test_HLA[dataset_src_col_label] = df_test_HLA[dataset_src_col_label].replace(\n",
    "        {True: 1, False: 0}\n",
    "    )\n",
    "\n",
    "    test_peptides = df_test_HLA.peptide.values\n",
    "    HLA_sequences = df_test_HLA.Sequence.values\n",
    "    test_labels_with_hla = df_test_HLA.label.values\n",
    "\n",
    "del df_test_HLA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ee02ca",
   "metadata": {},
   "source": [
    "Tokenize and concat the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea022e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_input(peptide_sequences, HLA_sequences):\n",
    "    tokenized_sequence = []\n",
    "\n",
    "    for index in tqdm(range(0, len(peptide_sequences)), desc=\"Tokenizing inputs\"):\n",
    "        peptide = peptide_sequences[index]\n",
    "        HLA = HLA_sequences[index]\n",
    "\n",
    "        tokenized_peptide = [tokenizer.encode(peptide)]\n",
    "        tokenized_HLA = [tokenizer.encode(HLA)]\n",
    "\n",
    "        result = np.concatenate((tokenized_peptide, tokenized_HLA[0][1:]), axis=None)\n",
    "\n",
    "        tokenized_sequence.append(result)\n",
    "\n",
    "    return tokenized_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8506877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_peptide = tokenize_input(test_peptides, HLA_sequences)\n",
    "\n",
    "tokenized_test = pad_sequences(\n",
    "    [sent for sent in tokenized_peptide],\n",
    "    dtype=\"long\",\n",
    "    truncating=\"post\",\n",
    "    padding=\"post\",\n",
    ")\n",
    "\n",
    "test_inputs = torch.tensor(tokenized_test)\n",
    "test_labels = torch.tensor(test_labels_with_hla)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_labels)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ee21c",
   "metadata": {},
   "source": [
    "Load and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(weights_hla_file))\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e5642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(temp_output_hla_file, \"w\") as f:\n",
    "    pass\n",
    "with open(temp_output_hla_flat_file, \"w\") as f:\n",
    "    pass\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for batch in tqdm(test_dataloader, desc=\"Testing 'with HLA' model\"):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(b_input_ids)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    with open(temp_output_hla_file, \"a\") as f:\n",
    "        for elem in logits[:, 1]:\n",
    "            f.write(str(elem) + \" \")\n",
    "\n",
    "    flat_predictions = np.argmax(logits, axis=1).flatten()\n",
    "    with open(temp_output_hla_flat_file, \"a\") as f:\n",
    "        for elem in flat_predictions:\n",
    "            f.write(str(elem) + \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266664fd",
   "metadata": {},
   "source": [
    "Read output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ad84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(temp_output_no_hla_flat_file, \"r\") as f:\n",
    "    data = f.read()\n",
    "data_list = data.split(\" \")\n",
    "array_list = np.array(data_list[:-1])\n",
    "no_HLA_predictions_f = array_list.astype(int)\n",
    "os.remove(temp_output_no_hla_flat_file)\n",
    "\n",
    "with open(temp_output_hla_flat_file, \"r\") as f:\n",
    "    data = f.read()\n",
    "data_list = data.split(\" \")\n",
    "array_list = np.array(data_list[:-1])\n",
    "HLA_predictions_f = array_list.astype(int)\n",
    "os.remove(temp_output_hla_flat_file)\n",
    "\n",
    "print(\"No HLA:\")\n",
    "acc_no_hla = metrics.accuracy_score(test_labels_no_hla, no_HLA_predictions_f)\n",
    "print(f\"Accuracy: {acc_no_hla}\")\n",
    "f1_no_hla = metrics.f1_score(test_labels_no_hla, no_HLA_predictions_f)\n",
    "print(f\"F1: {f1_no_hla}\")\n",
    "prec_no_hla = metrics.precision_score(test_labels_no_hla, no_HLA_predictions_f)\n",
    "print(f\"Precision: {prec_no_hla}\")\n",
    "rec_no_hla = metrics.recall_score(test_labels_no_hla, no_HLA_predictions_f)\n",
    "print(f\"Recall: {rec_no_hla}\")\n",
    "print()\n",
    "print(\"With HLA:\")\n",
    "acc_with_hla = metrics.accuracy_score(test_labels_with_hla, HLA_predictions_f)\n",
    "print(f\"Accuracy: {acc_with_hla}\")\n",
    "f1_with_hla = metrics.f1_score(test_labels_with_hla, HLA_predictions_f)\n",
    "print(f\"F1: {f1_with_hla}\")\n",
    "prec_with_hla = metrics.precision_score(test_labels_with_hla, HLA_predictions_f)\n",
    "print(f\"Precision: {prec_with_hla}\")\n",
    "rec_with_hla = metrics.recall_score(test_labels_with_hla, HLA_predictions_f)\n",
    "print(f\"Recall: {rec_with_hla}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187536d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(temp_output_no_hla_file, \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "data_list = data.split(\" \")\n",
    "\n",
    "array_list = np.array(data_list[:-1])\n",
    "no_HLA_predictions = array_list.astype(float)\n",
    "\n",
    "os.remove(temp_output_no_hla_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2746d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(temp_output_hla_file, \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "data_list = data.split(\" \")\n",
    "\n",
    "array_list = np.array(data_list[:-1])\n",
    "HLA_predictions = array_list.astype(float)\n",
    "\n",
    "os.remove(temp_output_hla_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd389a4e",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2289420",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_no_HLA, tpr_no_HLA, _ = metrics.roc_curve(test_labels_no_hla, no_HLA_predictions)\n",
    "auc_no_HLA = metrics.roc_auc_score(test_labels_no_hla, no_HLA_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_HLA, tpr_HLA, _ = metrics.roc_curve(test_labels_with_hla, HLA_predictions)\n",
    "auc_HLA = metrics.roc_auc_score(test_labels_with_hla, HLA_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79165593",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_round = 5\n",
    "\n",
    "auc_no_HLA = round(auc_no_HLA, auc_round)\n",
    "auc_HLA = round(auc_HLA, auc_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581ca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.plot(\n",
    "    fpr_no_HLA,\n",
    "    tpr_no_HLA,\n",
    "    label=\"Without HLA (AUC=\" + str(auc_no_HLA) + \")\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.plot(fpr_HLA, tpr_HLA, label=\"With HLA (AUC=\" + str(auc_HLA) + \")\", linewidth=2)\n",
    "\n",
    "plt.ylabel(\"True positive rate\", fontsize=24)\n",
    "plt.xlabel(\"False positive rate\", fontsize=24)\n",
    "plt.title(f\"ROC curve comparison: {exp_name}\", fontsize=24, pad=20)\n",
    "\n",
    "plt.grid(linestyle=\"--\")\n",
    "\n",
    "_ = plt.legend(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee4d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "w = 0.4\n",
    "\n",
    "plt.bar(\n",
    "    [0 - w / 2, 1 - w / 2, 2 - w / 2, 3 - w / 2],\n",
    "    [acc_no_hla, f1_no_hla, prec_no_hla, rec_no_hla],\n",
    "    color=\"C0\",\n",
    "    label=\"Without HLA\",\n",
    "    width=w,\n",
    ")\n",
    "\n",
    "plt.bar(\n",
    "    [0 + w / 2, 1 + w / 2, 2 + w / 2, 3 + w / 2],\n",
    "    [acc_with_hla, f1_with_hla, prec_with_hla, rec_with_hla],\n",
    "    color=\"C1\",\n",
    "    label=\"With HLA\",\n",
    "    width=w,\n",
    ")\n",
    "\n",
    "plt.xticks([0, 1, 2, 3], [\"Accuracy\", \"F1\", \"Precision\", \"Recall\"], fontsize=12)\n",
    "\n",
    "_ = plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83f14f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
