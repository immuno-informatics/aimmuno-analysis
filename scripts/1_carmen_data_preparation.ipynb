{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07580322",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea17928",
   "metadata": {},
   "source": [
    "Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09ea8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af130ab",
   "metadata": {},
   "source": [
    "Set the paths of the input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc1f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"/path/to/project/root\"\n",
    "\n",
    "data_dir = project_dir + \"/data\"\n",
    "\n",
    "df_train_file = data_dir + \"/datasets/carmen_initial_dataset/training_set.csv\"\n",
    "df_test_file = data_dir + \"/datasets/carmen_initial_dataset/test_set.csv\"\n",
    "\n",
    "protein_sequence_file = data_dir + \"/datasets/carmen_initial_dataset/protein_sequences.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3647ea",
   "metadata": {},
   "source": [
    "Select experiment type and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08505bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"carmen_balanced_1_1\"\n",
    "data_balanced = True\n",
    "n_false_peps = 1\n",
    "\n",
    "# exp_name = \"carmen_balanced_1_5\"\n",
    "# data_balanced = True\n",
    "# n_false_peps = 5\n",
    "\n",
    "# exp_name = \"carmen_unbalanced_1_1\"\n",
    "# data_balanced = False\n",
    "# n_false_peps = 1\n",
    "\n",
    "# exp_name = \"carmen_unbalanced_1_5\"\n",
    "# data_balanced = False\n",
    "# n_false_peps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48918722",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = data_dir + f\"/datasets/{exp_name}\"\n",
    "output_test_file = output_dir + \"/test_set.csv\"\n",
    "output_train_file = output_dir + \"/training_set.csv\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c982c25",
   "metadata": {},
   "source": [
    "# Step 1 loading the training and the test set\n",
    "\n",
    "Import the training and the test dataset from the CARMEN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe42eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(df_train_file)\n",
    "df_test = pd.read_csv(df_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ef5e84",
   "metadata": {},
   "source": [
    "Adding protein sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6eb821",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_sequence = pd.read_csv(protein_sequence_file)\n",
    "protein_sequence = protein_sequence.rename(columns={'name' : 'Protein_id'})\n",
    "\n",
    "df_train = pd.merge(df_train, protein_sequence, how=\"left\", on=[\"Protein_id\"])\n",
    "df_test = pd.merge(df_test, protein_sequence, how=\"left\", on=[\"Protein_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d1e52",
   "metadata": {},
   "source": [
    "Cleaning step\n",
    "\n",
    "Delete all duplicates within the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_balanced:\n",
    "    print('Dataset size with repetition --> '+str(len(df_train)))\n",
    "    df_train = df_train.drop_duplicates(subset=['peptide'], keep='first', ignore_index=True)\n",
    "    print('Dataset size without repetition --> '+str(len(df_train)))\n",
    "\n",
    "    print('Dataset size with repetition --> '+str(len(df_test)))\n",
    "    df_test = df_test.drop_duplicates(subset=['peptide'], keep='first', ignore_index=True)\n",
    "    print('Dataset size without repetition --> '+str(len(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6e3170",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, df_test, how ='outer',  on=['peptide'], indicator=True).query('_merge == \"left_only\"')\n",
    "df_train.rename(columns={'HLA_x': 'HLA', 'Netmhcpan_binder_x' : 'Netmhcpan_binder',\n",
    "                        'Protein_id_x': 'Protein_id', 'sequence_x': 'sequence'}, inplace=True)\n",
    "\n",
    "df_train = df_train.drop(columns=['HLA_y', '_merge', 'Netmhcpan_binder_y', 'Protein_id_y','sequence_y'])\n",
    "df_train = df_train.drop_duplicates(keep='first', ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fc9707",
   "metadata": {},
   "source": [
    "# Step 2 - Fake peptides generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf68684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_train = np.unique(df_train.peptide, return_counts = False)\n",
    "unique_test = np.unique(df_test.peptide, return_counts = False)\n",
    "\n",
    "peptides = np.concatenate((unique_train, unique_test), axis=None)\n",
    "\n",
    "UNIQUE_PEPS = np.unique(peptides, return_counts = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64324d4",
   "metadata": {},
   "source": [
    "Save all the unique peptides in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ef3d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictio_pepts = {}\n",
    "\n",
    "for key in UNIQUE_PEPS:\n",
    "    dictio_pepts[key] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91da4a7",
   "metadata": {},
   "source": [
    "Function: `false_possible_indicies`\n",
    "\n",
    "Purpose:\n",
    "* Generates random start and end indices for a potential false peptide sequence within a given sequence.\n",
    "* Ensures that the generated indices do not overlap with the indices of a true peptide.\n",
    "\n",
    "Parameters:\n",
    "* `sequence`: The input sequence.\n",
    "* `true_peptide`: The true peptide sequence within the input sequence.\n",
    "\n",
    "Returns:\n",
    "* A tuple containing the start and end indices of the potential false peptide sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_possible_indicies(sequence, true_peptide):\n",
    "    len_peptide = len(true_peptide)\n",
    "\n",
    "    start_index = sequence.find(true_peptide)\n",
    "    end_index = start_index+len_peptide\n",
    "\n",
    "    false_start = random.randint(0, (len(sequence)-len_peptide)-1)\n",
    "    false_end = false_start + len_peptide\n",
    "\n",
    "    if(false_start in range(start_index, end_index) or false_end in range(start_index, end_index)):\n",
    "        false_start = random.randint(0, (len(sequence)-len_peptide)-1)\n",
    "        false_end = false_start + len_peptide\n",
    "\n",
    "    return false_start, false_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f7c42e",
   "metadata": {},
   "source": [
    "Function: `create_false_string`\n",
    "\n",
    "Purpose:\n",
    "* Creates a false peptide sequence based on the provided start and end indices.\n",
    "* Checks if the generated false peptide contains invalid characters ('U', 'X', '*') or if it's already present in a dictionary of known peptides.\n",
    "\n",
    "Parameters:\n",
    "* `sequence`: The input sequence.\n",
    "* `false_start`: The starting index of the potential false peptide.\n",
    "* `false_end`: The ending index of the potential false peptide.\n",
    "\n",
    "Returns:\n",
    "* A tuple containing the generated false peptide string and a flag indicating its validity:\n",
    "  * 0: The false peptide is invalid (contains invalid characters or is already in the dictionary).\n",
    "  * 1: The false peptide is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a794f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_false_string(sequence, false_start, false_end):\n",
    "    sequence_list = list(sequence)\n",
    "    false_peptide = sequence_list[false_start: false_end]\n",
    "\n",
    "    false_peptide_string = \"\".join(false_peptide)\n",
    "\n",
    "    if ('U' in false_peptide_string) or ('X' in false_peptide_string) or ('*' in false_peptide_string):\n",
    "        return false_peptide_string, 0\n",
    "\n",
    "    if false_peptide_string in dictio_pepts:\n",
    "        return false_peptide_string, 0\n",
    "\n",
    "    else:\n",
    "        return false_peptide_string, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d647ca",
   "metadata": {},
   "source": [
    "Function: `false_peptide`\n",
    "\n",
    "Purpose:\n",
    "* Generates a valid false peptide sequence within a given sequence, ensuring it doesn't overlap with the true peptide and doesn't contain invalid characters or exist in a known peptide dictionary.\n",
    "\n",
    "Parameters:\n",
    "* `sequence`: The input sequence.\n",
    "* `true_peptide`: The true peptide sequence within the input sequence.\n",
    "\n",
    "Returns:\n",
    "* A valid false peptide sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a347fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_peptide(sequence, true_peptide):\n",
    "    flag = 0\n",
    "\n",
    "    while flag != 1:\n",
    "        false_start, false_end = false_possible_indicies(sequence, true_peptide)\n",
    "        false_peptide, flag = create_false_string(sequence, false_start, false_end)\n",
    "\n",
    "    return false_peptide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7ca446",
   "metadata": {},
   "source": [
    "Function: `create_dataframe_with_false_example`\n",
    "\n",
    "Purpose:\n",
    "* Augments an existing DataFrame with additional rows representing false peptide examples.\n",
    "* For each peptide in the original DataFrame, it generates a specified number of false peptide sequences based on the given sequence and true peptide.\n",
    "* Assigns appropriate labels, HLA values, and NetMHCpan binder predictions to these new rows.\n",
    "\n",
    "Parameters:\n",
    "* `df`: The original DataFrame containing peptide, sequence, HLA, and NetMHCpan_binder information.\n",
    "* `num_false`: The number of false peptide examples to generate for each original peptide.\n",
    "\n",
    "Returns:\n",
    "* A new DataFrame containing the original rows and the newly generated false peptide examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78818a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_with_false_example(df, num_false):\n",
    "    d = {}\n",
    "    peptidi = []\n",
    "    label = []\n",
    "    HLA = []\n",
    "    binder = []\n",
    "\n",
    "    for index in tqdm(range(0, len(df), 1)):\n",
    "        peptide = df.iloc[index]['peptide']\n",
    "        sequence = df.iloc[index]['sequence']\n",
    "        HLA_value = df.iloc[index]['HLA']\n",
    "        pan = df.iloc[index]['Netmhcpan_binder']\n",
    "\n",
    "        flag = 0\n",
    "\n",
    "        for false in range(num_false):\n",
    "            if type(sequence) == str and len(sequence) > 50:\n",
    "                HLAs = HLA_value.split(',')\n",
    "                for hla in HLAs:\n",
    "                    false_pep = false_peptide(sequence, peptide)\n",
    "                    peptidi.append(false_pep)\n",
    "                    label.append(0)\n",
    "                    HLA.append(hla)\n",
    "                    binder.append('F')\n",
    "                flag = 1\n",
    "\n",
    "        if flag == 1:\n",
    "            HLAs = HLA_value.split(',')\n",
    "            for hla in HLAs:\n",
    "                peptidi.append(peptide)\n",
    "                label.append(1)\n",
    "                HLA.append(hla)\n",
    "                binder.append(pan)\n",
    "\n",
    "    d['peptide'] = peptidi\n",
    "    d['label'] = label\n",
    "    d['HLA'] = HLA\n",
    "    d['Netmhcpan_binder'] = binder\n",
    "\n",
    "    result = pd.DataFrame(data=d)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5ede54",
   "metadata": {},
   "source": [
    "# STEP 3 - Call the functions and generate the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee87327",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_with_false = create_dataframe_with_false_example(df_train, n_false_peps)\n",
    "df_test_with_false = create_dataframe_with_false_example(df_test, n_false_peps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d837702",
   "metadata": {},
   "source": [
    "Deletion of common peptides in both datasets\n",
    "\n",
    "All records containing the pair `<peptide, label>` also present in the test set are removed from the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_with_false = pd.merge(df_train_with_false, df_test_with_false, how ='outer',  on=['peptide', 'label'], indicator=True).query('_merge == \"left_only\"')\n",
    "df_train_with_false.rename(columns={'HLA_x': 'HLA', 'Netmhcpan_binder_x' : 'Netmhcpan_binder'}, inplace=True)\n",
    "\n",
    "df_train_with_false = df_train_with_false.drop(columns=['HLA_y', '_merge', 'Netmhcpan_binder_y'])\n",
    "df_train_with_false = df_train_with_false.drop_duplicates(keep='first', ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa0d305",
   "metadata": {},
   "source": [
    "Save the new datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03d2d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_with_false.to_csv(output_train_file, encoding='utf-8', index=False)\n",
    "df_test_with_false.to_csv(output_test_file, encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
